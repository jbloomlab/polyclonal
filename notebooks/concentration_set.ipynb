{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866cd98e-8687-4b7c-a1f4-3b23bb06392e",
   "metadata": {},
   "source": [
    "# What set of concentrations should we use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc265a-fd96-4954-973b-50750dd64b84",
   "metadata": {},
   "source": [
    "We have simulated noisy data measured at 6 concentrations [0.125, 0.25, 0.5, 1, 2, 4]. The goal is to figure out what set of concentrations to use in actual experiments. Formally, we can write the problem as: what is the optimal set of concentrations that provides the best performance while minimizing the **concentrations** used and the **number of concentrations** used? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca210a-5bdc-4b92-83a5-4cd5752efc32",
   "metadata": {},
   "source": [
    "If we perform an exhaustive grid search, there are $2^{6} - 1 = 63$ sets of concentrations to test. I am not going to do that.  \n",
    "\n",
    "Instead, I first looked at the effect of adding a higher concentration to a set starting at concentration = 0.125. This involved training models on 6 sets of concentrations (Experiment 1).\n",
    "1. 0.125\n",
    "2. 0.125, 0.25\n",
    "3. 0.125, 0.25, 0.5\n",
    "4. 0.125, 0.25, 0.5, 1\n",
    "5. 0.125, 0.25, 0.5, 1, 2\n",
    "6. 0.125, 0.25, 0.5, 1, 2, 4  \n",
    "\n",
    "I found that the concentration set [0.125, 0.25, 0.5, 1, 2] was the (slightly conservative) point when adding another higher concentration did not contribute to increasing the model performance. I then asked, if I start at concentration = 2, at what point does adding back a lower concentration not improve the model performance? This involved training models on 5 sets of concentrations (Experiment 2). \n",
    "1. 2\n",
    "2. 1, 2\n",
    "3. 0.5, 1, 2\n",
    "4. 0.25, 0.5, 1, 2\n",
    "5. 0.125, 0.25, 0.5, 1, 2  \n",
    "\n",
    "I found that the concentration set [0.5, 1, 2] was good enough. To then check if three was the optimal number of concentrations, I removed the intermediate concentration and trained a model on the concentration set [0.5, 2]. As expected, removed this intermediate concentration lowered the predictive accuracy (especially for the class 1 epitope). I also repeated this with [0.25, 1, 4] and [0.25, 4].  \n",
    "\n",
    "Lastly, I compare the set of concentrations that appeared most optimal, [0.5, 1, 2] and [0.125, 1, 4] (tested in previous notebook here), to the model trained on all 6 concentrations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d03bca4-7ff2-4035-bba3-1df225aa201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polyclonal\n",
    "import pickle\n",
    "import random\n",
    "import altair as alt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d7fb70-a0dc-45cb-b39e-30cfe821d0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>library</th>\n",
       "      <th>aa_substitutions</th>\n",
       "      <th>concentration</th>\n",
       "      <th>prob_escape</th>\n",
       "      <th>IC90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td></td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.04859</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td></td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.17970</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td></td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.13200</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td></td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.07772</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td></td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.17960</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179995</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td>Y449I L518Y C525R L461I</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.02197</td>\n",
       "      <td>2.3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179996</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td>Y449V K529R N394R</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.9473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179997</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td>Y451L N481T F490V</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.02315</td>\n",
       "      <td>0.9301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179998</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td>Y453R V483G L492V N501P I332P</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179999</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td>Y489Q N501Y</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         library               aa_substitutions  concentration  prob_escape  \\\n",
       "0       avg3muts                                         0.125      0.04859   \n",
       "1       avg3muts                                         0.125      0.17970   \n",
       "2       avg3muts                                         0.125      0.13200   \n",
       "3       avg3muts                                         0.125      0.07772   \n",
       "4       avg3muts                                         0.125      0.17960   \n",
       "...          ...                            ...            ...          ...   \n",
       "179995  avg3muts        Y449I L518Y C525R L461I          4.000      0.02197   \n",
       "179996  avg3muts              Y449V K529R N394R          4.000      0.04925   \n",
       "179997  avg3muts              Y451L N481T F490V          4.000      0.02315   \n",
       "179998  avg3muts  Y453R V483G L492V N501P I332P          4.000      0.00000   \n",
       "179999  avg3muts                    Y489Q N501Y          4.000      0.00000   \n",
       "\n",
       "          IC90  \n",
       "0       0.1128  \n",
       "1       0.1128  \n",
       "2       0.1128  \n",
       "3       0.1128  \n",
       "4       0.1128  \n",
       "...        ...  \n",
       "179995  2.3100  \n",
       "179996  0.9473  \n",
       "179997  0.9301  \n",
       "179998  5.0120  \n",
       "179999  0.5881  \n",
       "\n",
       "[180000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_data = (\n",
    "    pd.read_csv('RBD_variants_escape_noisy.csv', na_filter=None)\n",
    "    .query(\"library == 'avg3muts'\")\n",
    "    .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "noisy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61fd651-b12b-4475-817a-177f62eeb4d7",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e601a1f-68c9-4348-8465-6bc0a17f5899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Thu Nov 25 12:21:04 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.027545      11737      11737    0.29701          0\n",
      "        500     10.994     498.23     494.26     3.9742          0\n",
      "        602     13.243     498.15      494.2     3.9484          0\n",
      "# Successfully finished at Thu Nov 25 12:21:17 2021.\n",
      "# Starting optimization of 5799 parameters at Thu Nov 25 12:21:17 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0    0.02994     659.14      613.8     45.343 6.2482e-30\n",
      "        500     13.043     308.91     243.81     46.213     18.892\n",
      "       1000     25.757     304.79     240.71     44.162     19.911\n",
      "       1500     38.799     302.65     239.55     42.997     20.101\n",
      "       1546     39.989     302.62     239.55     42.978     20.101\n",
      "# Successfully finished at Thu Nov 25 12:21:57 2021.\n",
      "Model fit on library with 1 concentrations beginning at c=0.125 to scipy_results/conc_exp1_noisy_1conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Thu Nov 25 12:21:59 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.046351      22053      22052    0.29701          0\n",
      "        500     27.118     1165.9     1161.7     4.2085          0\n",
      "        521     28.211     1165.9     1161.7     4.2156          0\n",
      "# Successfully finished at Thu Nov 25 12:22:27 2021.\n",
      "# Starting optimization of 5799 parameters at Thu Nov 25 12:22:27 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.049244     1431.8     1383.8     48.056 7.0575e-30\n",
      "        500      36.73     634.46     560.63     50.239      23.59\n",
      "        945     68.671     632.12      559.4     49.156     23.559\n",
      "# Successfully finished at Thu Nov 25 12:23:36 2021.\n",
      "Model fit on library with 2 concentrations beginning at c=0.125 to scipy_results/conc_exp1_noisy_2conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Thu Nov 25 12:23:38 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.088323      29827      29826    0.29701          0\n",
      "        500     48.784     1946.2     1941.8     4.4164          0\n",
      "        517     50.405     1946.2     1941.8     4.4202          0\n",
      "# Successfully finished at Thu Nov 25 12:24:28 2021.\n",
      "# Starting optimization of 5799 parameters at Thu Nov 25 12:24:28 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0    0.10595     2288.3     2238.3     50.027 1.0418e-29\n",
      "        500     51.339     962.06     879.72     53.328      29.02\n",
      "       1000      102.9     956.87     876.05     51.903      28.92\n",
      "       1500     153.71     955.41     875.69     50.508     29.206\n",
      "       2000     206.52      953.5     874.79     49.333     29.382\n",
      "       2052     211.69     953.46     874.76     49.315     29.387\n",
      "# Successfully finished at Thu Nov 25 12:28:00 2021.\n",
      "Model fit on library with 3 concentrations beginning at c=0.125 to scipy_results/conc_exp1_noisy_3conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Thu Nov 25 12:28:03 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.089433      35144      35144    0.29701          0\n",
      "        500     61.449     2752.9     2748.4     4.4327          0\n",
      "        961     117.12     2747.4     2742.7     4.6635          0\n",
      "# Successfully finished at Thu Nov 25 12:30:00 2021.\n",
      "# Starting optimization of 5799 parameters at Thu Nov 25 12:30:00 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0    0.11002     3138.5     3086.3     52.261 9.0796e-30\n",
      "        500     69.556     1260.2     1170.4     55.931     33.856\n",
      "       1000     139.97     1247.7     1159.3     54.662      33.76\n",
      "       1500     211.72       1245     1157.9     53.222     33.887\n",
      "       1650     233.43     1244.3     1157.4     52.964     33.964\n",
      "# Successfully finished at Thu Nov 25 12:33:53 2021.\n",
      "Model fit on library with 4 concentrations beginning at c=0.125 to scipy_results/conc_exp1_noisy_4conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Thu Nov 25 12:33:56 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0    0.16994      38615      38615    0.29701          0\n",
      "        500     75.015     3513.4     3508.5     4.9104          0\n",
      "       1000     148.83       3501       3496     4.9762          0\n",
      "       1340     199.61     3499.9     3494.9     4.9808          0\n",
      "# Successfully finished at Thu Nov 25 12:37:16 2021.\n",
      "# Starting optimization of 5799 parameters at Thu Nov 25 12:37:16 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0    0.13651       3924     3868.6     55.335 1.2985e-29\n",
      "        500     84.639     1547.9     1450.2     58.484     39.152\n",
      "       1000     168.13       1523     1426.5      57.14     39.358\n",
      "       1500     253.36     1509.8     1414.1     56.193     39.514\n",
      "       2000      336.2     1507.1       1413     54.732     39.332\n",
      "       2397     401.85     1505.4     1411.7     54.097     39.637\n",
      "# Successfully finished at Thu Nov 25 12:43:58 2021.\n",
      "Model fit on library with 5 concentrations beginning at c=0.125 to scipy_results/conc_exp1_noisy_5conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Thu Nov 25 12:44:01 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0    0.16865      40831      40831    0.29701          0\n",
      "        500     89.106     4202.7     4197.3     5.4026          0\n",
      "       1000     175.46     4186.6     4179.6     7.0049          0\n",
      "       1266     222.35     4184.4     4177.1     7.3131          0\n",
      "# Successfully finished at Thu Nov 25 12:47:44 2021.\n",
      "# Starting optimization of 5799 parameters at Thu Nov 25 12:47:44 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0    0.18757     4658.7     4575.6     83.053 1.6086e-29\n",
      "        500     100.19     2267.9     2168.9     81.423     17.576\n",
      "       1000     199.28     2241.8     2153.3     67.702     20.768\n",
      "       1500      297.2     2201.6     2122.6      54.54     24.502\n",
      "       2000     397.36     2061.5     1970.6     54.854     36.022\n",
      "       2500     495.43     1754.5     1652.4     55.621     46.401\n",
      "       3000     589.86     1737.6     1637.3     55.508     44.854\n",
      "       3173     618.63     1737.4       1637     55.625      44.83\n",
      "# Successfully finished at Thu Nov 25 12:58:03 2021.\n",
      "Model fit on library with 6 concentrations beginning at c=0.125 to scipy_results/conc_exp1_noisy_6conc_3muts.pkl\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "\n",
    "conc = [0.125, 0.25, 0.5, 1, 2, 4]\n",
    "for i in range(1,7):\n",
    "    poly_abs = polyclonal.Polyclonal(data_to_fit=noisy_data.query(f\"concentration in {conc[0:i]}\"),\n",
    "                                     activity_wt_df=pd.DataFrame.from_records(\n",
    "                                         [('1', 1.0),\n",
    "                                          ('2', 3.0),\n",
    "                                          ('3', 2.0),\n",
    "                                          ],\n",
    "                                         columns=['epitope', 'activity'],\n",
    "                                         ),\n",
    "                                     site_escape_df=pd.DataFrame.from_records(\n",
    "                                         [('1', 417, 10.0),\n",
    "                                          ('2', 484, 10.0),\n",
    "                                          ('3', 444, 10.0),\n",
    "                                          ],\n",
    "                                         columns=['epitope', 'site', 'escape'],\n",
    "                                         ),\n",
    "                                     data_mut_escape_overlap='fill_to_data',\n",
    "                                 )\n",
    "    \n",
    "    opt_res = poly_abs.fit(logfreq=500)\n",
    "    pickle.dump(poly_abs, open(f'scipy_results/conc_exp1_noisy_{i}conc_3muts.pkl', 'wb'))\n",
    "    print(f\"Model fit on library with {i} concentrations beginning at c=0.125 to scipy_results/conc_exp1_noisy_{i}conc_3muts.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084f1704-8d80-4e68-9008-6e187f396b4e",
   "metadata": {},
   "source": [
    "## Get correlation between predicted and true beta coefficients for each trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61ab02ae-c221-4c5a-8f05-77f922959383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epitope</th>\n",
       "      <th>correlation</th>\n",
       "      <th>num_concentrations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class 1</td>\n",
       "      <td>0.679124</td>\n",
       "      <td>[0.125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class 2</td>\n",
       "      <td>0.694542</td>\n",
       "      <td>[0.125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class 3</td>\n",
       "      <td>0.480764</td>\n",
       "      <td>[0.125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class 1</td>\n",
       "      <td>0.773873</td>\n",
       "      <td>[0.125, 0.25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class 2</td>\n",
       "      <td>0.896795</td>\n",
       "      <td>[0.125, 0.25]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epitope  correlation num_concentrations\n",
       "0  class 1     0.679124            [0.125]\n",
       "1  class 2     0.694542            [0.125]\n",
       "2  class 3     0.480764            [0.125]\n",
       "0  class 1     0.773873      [0.125, 0.25]\n",
       "1  class 2     0.896795      [0.125, 0.25]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_corrs = pd.DataFrame({'epitope' : [], \n",
    "                          'correlation' : [], \n",
    "                          'num_concentrations' : []}\n",
    "                        )\n",
    "\n",
    "conc = [0.125, 0.25, 0.5, 1, 2, 4]\n",
    "for i in range(1,7):\n",
    "    model = pickle.load(open(f'scipy_results/conc_exp1_noisy_{i}conc_3muts.pkl', 'rb'))\n",
    "\n",
    "    mut_escape_pred = (\n",
    "        pd.read_csv('RBD_mut_escape_df.csv')\n",
    "        .merge((model.mut_escape_df\n",
    "                .assign(epitope=lambda x: 'class ' + x['epitope'].astype(str))\n",
    "                .rename(columns={'escape': 'predicted escape'})\n",
    "                ),\n",
    "               on=['mutation', 'epitope'],\n",
    "               validate='one_to_one',\n",
    "               )\n",
    "        )\n",
    "\n",
    "    corr = (mut_escape_pred\n",
    "            .groupby('epitope')\n",
    "            .apply(lambda x: x['escape'].corr(x['predicted escape']))\n",
    "            .rename('correlation')\n",
    "            .reset_index()\n",
    "            )\n",
    "    all_corrs = pd.concat([all_corrs, \n",
    "                           corr.assign(num_concentrations = [str(conc[0:i])] * len(corr.index))]\n",
    "                         )\n",
    "all_corrs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08205f69-3471-4f3b-85eb-ef423cab4e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-c1d535efa5794032a2eae3ac9977b79d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-c1d535efa5794032a2eae3ac9977b79d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-c1d535efa5794032a2eae3ac9977b79d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-9ded52a1f5c90f50ba0b2deb9ffe8481\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"num_concentrations\", \"sort\": {\"field\": \"color\", \"order\": \"descending\"}, \"type\": \"nominal\"}, \"column\": {\"field\": \"epitope\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"num_concentrations\", \"type\": \"nominal\"}, {\"field\": \"correlation\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"labels\": false}, \"field\": \"num_concentrations\", \"sort\": {\"field\": \"x\", \"order\": \"descending\"}, \"type\": \"ordinal\"}, \"y\": {\"field\": \"correlation\", \"type\": \"quantitative\"}}, \"height\": 200, \"width\": 125, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-9ded52a1f5c90f50ba0b2deb9ffe8481\": [{\"epitope\": \"class 1\", \"correlation\": 0.6791242580385397, \"num_concentrations\": \"[0.125]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.6945418516540638, \"num_concentrations\": \"[0.125]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.48076435129355277, \"num_concentrations\": \"[0.125]\"}, {\"epitope\": \"class 1\", \"correlation\": 0.7738729798478133, \"num_concentrations\": \"[0.125, 0.25]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.896795088828361, \"num_concentrations\": \"[0.125, 0.25]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.8280669355227267, \"num_concentrations\": \"[0.125, 0.25]\"}, {\"epitope\": \"class 1\", \"correlation\": 0.8012182298946373, \"num_concentrations\": \"[0.125, 0.25, 0.5]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.952060429000577, \"num_concentrations\": \"[0.125, 0.25, 0.5]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.9131178888393936, \"num_concentrations\": \"[0.125, 0.25, 0.5]\"}, {\"epitope\": \"class 1\", \"correlation\": 0.860184815835272, \"num_concentrations\": \"[0.125, 0.25, 0.5, 1]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9605134709679458, \"num_concentrations\": \"[0.125, 0.25, 0.5, 1]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.92721916033429, \"num_concentrations\": \"[0.125, 0.25, 0.5, 1]\"}, {\"epitope\": \"class 1\", \"correlation\": 0.8804037423305416, \"num_concentrations\": \"[0.125, 0.25, 0.5, 1, 2]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9704899284272651, \"num_concentrations\": \"[0.125, 0.25, 0.5, 1, 2]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.9503921607331711, \"num_concentrations\": \"[0.125, 0.25, 0.5, 1, 2]\"}, {\"epitope\": \"class 1\", \"correlation\": 0.8756581891681191, \"num_concentrations\": \"[0.125, 0.25, 0.5, 1, 2, 4]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9763535533863456, \"num_concentrations\": \"[0.125, 0.25, 0.5, 1, 2, 4]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.9543748495394667, \"num_concentrations\": \"[0.125, 0.25, 0.5, 1, 2, 4]\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(all_corrs).mark_bar().encode(\n",
    "    x= alt.X('num_concentrations:O', axis=alt.Axis(labels=False), sort=alt.EncodingSortField('x', order='descending')),\n",
    "    y='correlation:Q',\n",
    "    color=alt.Color('num_concentrations:N', sort=alt.EncodingSortField('color', order='descending')),\n",
    "    column='epitope:N',\n",
    "    tooltip = ['num_concentrations', 'correlation']\n",
    ").properties(width=125, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d29f1a-4018-4398-ae90-6416be414203",
   "metadata": {},
   "source": [
    "The [0.125, 0.25, 0.5, 1, 2] set appears to be point when adding an additional concentration doesn't improve the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a70a1-2795-45aa-80ac-ace36bdde4d4",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "566095da-d021-4d4f-b684-5926124574cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Thu Nov 25 21:42:13 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.017499     3471.2     3470.9    0.29701          0\n",
      "        500     8.9243      728.3     723.65     4.6463          0\n",
      "        989     17.323      727.5     722.28     5.2223          0\n",
      "# Successfully finished at Thu Nov 25 21:42:30 2021.\n",
      "# Starting optimization of 5799 parameters at Thu Nov 25 21:42:30 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.019306     811.19     753.78     57.412 1.0546e-29\n",
      "        500     9.9185     291.36     213.98     50.167     27.208\n",
      "       1000     19.781     274.78     199.14     47.256      28.38\n",
      "       1240     24.452     274.29     198.73     47.008     28.551\n",
      "# Successfully finished at Thu Nov 25 21:42:54 2021.\n",
      "Model fit on library with 1 concentrations beginning at c=2 to scipy_results/conc_exp2_noisy_1conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Thu Nov 25 21:42:56 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.046564     8788.8     8788.5    0.29701          0\n",
      "        500     22.913     1524.8     1520.1     4.6906          0\n",
      "       1000     45.524     1522.4     1516.7     5.6901          0\n",
      "       1073     48.834     1522.3     1516.6     5.6965          0\n",
      "# Successfully finished at Thu Nov 25 21:43:44 2021.\n",
      "# Starting optimization of 5799 parameters at Thu Nov 25 21:43:45 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0    0.04532     1658.6     1596.1     62.455 1.5202e-29\n",
      "        500      25.19     647.27     557.08     59.629      30.56\n",
      "       1000     50.073     583.78     496.56     53.519     33.701\n",
      "       1500     74.779     564.46     479.99     50.871     33.595\n",
      "       1827     90.759     563.65     480.01     50.094     33.547\n",
      "# Successfully finished at Thu Nov 25 21:45:15 2021.\n",
      "Model fit on library with 2 concentrations beginning at c=2 to scipy_results/conc_exp2_noisy_2conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Thu Nov 25 21:45:17 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.065682      16563      16563    0.29701          0\n",
      "        413      32.69     2310.8     2306.2     4.5767          0\n",
      "# Successfully finished at Thu Nov 25 21:45:50 2021.\n",
      "# Starting optimization of 5799 parameters at Thu Nov 25 21:45:50 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.076304     2513.4     2461.8     51.594 9.2581e-30\n",
      "        500      43.45     898.23     806.22     55.594     36.421\n",
      "       1000     86.884     889.62     799.61     53.962     36.056\n",
      "       1500     130.42      887.4      798.3     52.806     36.291\n",
      "       1965     170.12     886.38     797.35     52.443     36.579\n",
      "# Successfully finished at Thu Nov 25 21:48:40 2021.\n",
      "Model fit on library with 3 concentrations beginning at c=2 to scipy_results/conc_exp2_noisy_3conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Thu Nov 25 21:48:42 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0    0.08611      26878      26878    0.29701          0\n",
      "        427     41.647     2989.8     2985.1     4.7181          0\n",
      "# Successfully finished at Thu Nov 25 21:49:24 2021.\n",
      "# Starting optimization of 5799 parameters at Thu Nov 25 21:49:24 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.099602     3295.2     3241.8     53.395 8.4219e-30\n",
      "        500      57.08     1221.4     1126.6     57.209     37.582\n",
      "       1000     113.71     1204.2     1110.4      55.77     38.052\n",
      "       1500     169.66     1201.8     1109.1     54.699     38.091\n",
      "       2000      226.1     1199.9     1107.6     53.771     38.459\n",
      "       2351     265.54       1199     1106.7     53.595       38.7\n",
      "# Successfully finished at Thu Nov 25 21:53:50 2021.\n",
      "Model fit on library with 4 concentrations beginning at c=2 to scipy_results/conc_exp2_noisy_4conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Thu Nov 25 21:53:53 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0    0.10239      38615      38615    0.29701          0\n",
      "        500     59.014     3513.4     3508.5     4.9104          0\n",
      "       1000     117.09       3501       3496     4.9762          0\n",
      "       1340     157.02     3499.9     3494.9     4.9808          0\n",
      "# Successfully finished at Thu Nov 25 21:56:30 2021.\n",
      "# Starting optimization of 5799 parameters at Thu Nov 25 21:56:30 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0      0.124       3924     3868.6     55.335 1.2985e-29\n",
      "        500     70.562     1547.9     1450.2     58.484     39.152\n",
      "       1000     140.38       1523     1426.5      57.14     39.358\n",
      "       1500     211.68     1509.8     1414.1     56.193     39.514\n",
      "       2000     280.96     1507.1       1413     54.732     39.332\n",
      "       2397     335.83     1505.4     1411.7     54.097     39.637\n",
      "# Successfully finished at Thu Nov 25 22:02:05 2021.\n",
      "Model fit on library with 5 concentrations beginning at c=2 to scipy_results/conc_exp2_noisy_5conc_3muts.pkl\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "\n",
    "conc = [2, 1, 0.5, 0.25, 0.125]\n",
    "for i in range(1, len(conc)+1):\n",
    "    poly_abs = polyclonal.Polyclonal(data_to_fit=noisy_data.query(f\"concentration in {conc[0:i]}\"),\n",
    "                                     activity_wt_df=pd.DataFrame.from_records(\n",
    "                                         [('1', 1.0),\n",
    "                                          ('2', 3.0),\n",
    "                                          ('3', 2.0),\n",
    "                                          ],\n",
    "                                         columns=['epitope', 'activity'],\n",
    "                                         ),\n",
    "                                     site_escape_df=pd.DataFrame.from_records(\n",
    "                                         [('1', 417, 10.0),\n",
    "                                          ('2', 484, 10.0),\n",
    "                                          ('3', 444, 10.0),\n",
    "                                          ],\n",
    "                                         columns=['epitope', 'site', 'escape'],\n",
    "                                         ),\n",
    "                                     data_mut_escape_overlap='fill_to_data',\n",
    "                                 )\n",
    "    \n",
    "    opt_res = poly_abs.fit(logfreq=500)\n",
    "    pickle.dump(poly_abs, open(f'scipy_results/conc_exp2_noisy_{i}conc_3muts.pkl', 'wb'))\n",
    "    print(f\"Model fit on library with {i} concentrations beginning at c=2 to scipy_results/conc_exp2_noisy_{i}conc_3muts.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99047ea-0b12-41e5-b0e7-f54582e633c2",
   "metadata": {},
   "source": [
    "## Get correlation between predicted and true beta coefficients for each trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a33f59d-b187-4ba6-a2ed-b885277f01ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epitope</th>\n",
       "      <th>correlation</th>\n",
       "      <th>num_concentrations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class 1</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class 2</td>\n",
       "      <td>0.949397</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class 3</td>\n",
       "      <td>0.915621</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class 1</td>\n",
       "      <td>0.848612</td>\n",
       "      <td>[2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class 2</td>\n",
       "      <td>0.963036</td>\n",
       "      <td>[2, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epitope  correlation num_concentrations\n",
       "0  class 1     0.770642                [2]\n",
       "1  class 2     0.949397                [2]\n",
       "2  class 3     0.915621                [2]\n",
       "0  class 1     0.848612             [2, 1]\n",
       "1  class 2     0.963036             [2, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_corrs = pd.DataFrame({'epitope' : [], \n",
    "                          'correlation' : [], \n",
    "                          'num_concentrations' : []}\n",
    "                        )\n",
    "\n",
    "conc = [2, 1, 0.5, 0.25, 0.125]\n",
    "for i in range(1,6):\n",
    "    model = pickle.load(open(f'scipy_results/conc_exp2_noisy_{i}conc_3muts.pkl', 'rb'))\n",
    "\n",
    "    mut_escape_pred = (\n",
    "        pd.read_csv('RBD_mut_escape_df.csv')\n",
    "        .merge((model.mut_escape_df\n",
    "                .assign(epitope=lambda x: 'class ' + x['epitope'].astype(str))\n",
    "                .rename(columns={'escape': 'predicted escape'})\n",
    "                ),\n",
    "               on=['mutation', 'epitope'],\n",
    "               validate='one_to_one',\n",
    "               )\n",
    "        )\n",
    "\n",
    "    corr = (mut_escape_pred\n",
    "            .groupby('epitope')\n",
    "            .apply(lambda x: x['escape'].corr(x['predicted escape']))\n",
    "            .rename('correlation')\n",
    "            .reset_index()\n",
    "            )\n",
    "    all_corrs = pd.concat([all_corrs, \n",
    "                           corr.assign(num_concentrations = [str(conc[0:i])] * len(corr.index))]\n",
    "                         )\n",
    "all_corrs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c69d465-1f7e-4ff0-8fb4-f89fe7020c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-85bd53bf6b9b4ef886fbc31bf460907a\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-85bd53bf6b9b4ef886fbc31bf460907a\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-85bd53bf6b9b4ef886fbc31bf460907a\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-c094255a455cd382bff1a219501294f6\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"num_concentrations\", \"sort\": {\"field\": \"color\", \"order\": \"descending\"}, \"type\": \"nominal\"}, \"column\": {\"field\": \"epitope\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"num_concentrations\", \"type\": \"nominal\"}, {\"field\": \"correlation\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"labels\": false}, \"field\": \"num_concentrations\", \"sort\": {\"field\": \"x\", \"order\": \"descending\"}, \"type\": \"ordinal\"}, \"y\": {\"field\": \"correlation\", \"type\": \"quantitative\"}}, \"height\": 200, \"width\": 125, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-c094255a455cd382bff1a219501294f6\": [{\"epitope\": \"class 1\", \"correlation\": 0.770641548867928, \"num_concentrations\": \"[2]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.949396737341603, \"num_concentrations\": \"[2]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.9156211596122092, \"num_concentrations\": \"[2]\"}, {\"epitope\": \"class 1\", \"correlation\": 0.8486122162790036, \"num_concentrations\": \"[2, 1]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9630362168382519, \"num_concentrations\": \"[2, 1]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.9351667489282716, \"num_concentrations\": \"[2, 1]\"}, {\"epitope\": \"class 1\", \"correlation\": 0.8725033873875513, \"num_concentrations\": \"[2, 1, 0.5]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9683628090186779, \"num_concentrations\": \"[2, 1, 0.5]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.9462361627854732, \"num_concentrations\": \"[2, 1, 0.5]\"}, {\"epitope\": \"class 1\", \"correlation\": 0.8809061839914218, \"num_concentrations\": \"[2, 1, 0.5, 0.25]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9700908756118272, \"num_concentrations\": \"[2, 1, 0.5, 0.25]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.9494101314564393, \"num_concentrations\": \"[2, 1, 0.5, 0.25]\"}, {\"epitope\": \"class 1\", \"correlation\": 0.8804037423305416, \"num_concentrations\": \"[2, 1, 0.5, 0.25, 0.125]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9704899284272651, \"num_concentrations\": \"[2, 1, 0.5, 0.25, 0.125]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.9503921607331711, \"num_concentrations\": \"[2, 1, 0.5, 0.25, 0.125]\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(all_corrs).mark_bar().encode(\n",
    "    x= alt.X('num_concentrations:O', axis=alt.Axis(labels=False), sort=alt.EncodingSortField('x', order='descending')),\n",
    "    y='correlation:Q',\n",
    "    color=alt.Color('num_concentrations:N', sort=alt.EncodingSortField('color', order='descending')),\n",
    "    column='epitope:N',\n",
    "    tooltip = ['num_concentrations', 'correlation']\n",
    ").properties(width=125, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b32097-55f1-4fb0-95b8-0b82b0bf376d",
   "metadata": {},
   "source": [
    "It looks like the set [0.5, 1, 2] is sufficient. Now, lets try running a model on the set [0.5, 2], without the intermediate concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad07c014-c4f3-4676-8e33-47a2f6327b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Thu Nov 25 22:17:03 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.043393      11245      11245    0.29701          0\n",
      "        432     19.294     1520.4     1515.7      4.684          0\n",
      "# Successfully finished at Thu Nov 25 22:17:22 2021.\n",
      "# Starting optimization of 5799 parameters at Thu Nov 25 22:17:22 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.045623     1675.7     1623.1     52.562 1.0799e-29\n",
      "        500     25.072     616.27     526.96     55.267     34.039\n",
      "       1000     49.611      606.9     519.53     53.179     34.191\n",
      "       1500     74.015     605.05     518.13     52.066     34.852\n",
      "       2000     98.558     604.34     518.33     51.383     34.629\n",
      "       2053     101.13     604.32     518.28     51.409      34.63\n",
      "# Successfully finished at Thu Nov 25 22:19:04 2021.\n"
     ]
    }
   ],
   "source": [
    "poly_abs = polyclonal.Polyclonal(data_to_fit=noisy_data.query(f\"concentration in [0.5, 2]\"),\n",
    "                                     activity_wt_df=pd.DataFrame.from_records(\n",
    "                                         [('1', 1.0),\n",
    "                                          ('2', 3.0),\n",
    "                                          ('3', 2.0),\n",
    "                                          ],\n",
    "                                         columns=['epitope', 'activity'],\n",
    "                                         ),\n",
    "                                     site_escape_df=pd.DataFrame.from_records(\n",
    "                                         [('1', 417, 10.0),\n",
    "                                          ('2', 484, 10.0),\n",
    "                                          ('3', 444, 10.0),\n",
    "                                          ],\n",
    "                                         columns=['epitope', 'site', 'escape'],\n",
    "                                         ),\n",
    "                                     data_mut_escape_overlap='fill_to_data',\n",
    "                                 )\n",
    "    \n",
    "opt_res = poly_abs.fit(logfreq=500)\n",
    "pickle.dump(poly_abs, open(f'scipy_results/conc_exp2_noisy_2wointermediate_conc_3muts.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8805d23-7ea2-4e40-99ab-83ae76cf314b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epitope</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class 1</td>\n",
       "      <td>0.832552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class 2</td>\n",
       "      <td>0.967225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class 3</td>\n",
       "      <td>0.932690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epitope  correlation\n",
       "0  class 1     0.832552\n",
       "1  class 2     0.967225\n",
       "2  class 3     0.932690"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pickle.load(open(f'scipy_results/conc_exp2_noisy_2wointermediate_conc_3muts.pkl', 'rb'))\n",
    "\n",
    "mut_escape_pred = (\n",
    "        pd.read_csv('RBD_mut_escape_df.csv')\n",
    "        .merge((model.mut_escape_df\n",
    "                .assign(epitope=lambda x: 'class ' + x['epitope'].astype(str))\n",
    "                .rename(columns={'escape': 'predicted escape'})\n",
    "                ),\n",
    "               on=['mutation', 'epitope'],\n",
    "               validate='one_to_one',\n",
    "               )\n",
    "        )\n",
    "\n",
    "corr = (mut_escape_pred\n",
    "        .groupby('epitope')\n",
    "        .apply(lambda x: x['escape'].corr(x['predicted escape']))\n",
    "        .rename('correlation')\n",
    "        .reset_index()\n",
    "        )\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab9582c-0cf7-4d95-a48d-9a34e15d5c93",
   "metadata": {},
   "source": [
    "It looks like the intermediate concentration was important. The performance when training on [0.5, 2] was worse than that of [0.5, 1, 2], and comparable to when training on the two concentration example above ([1, 2])."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8444414-c3f1-4b5a-8bf6-ddb75f1bb277",
   "metadata": {},
   "source": [
    "From our experiments thus far, it appears that [0.5, 1, 2] is the most optimal set. However, we previously observed [here](mutation_rate.ipynb) that [0.25, 1, 4] actually slightly outperforms c = [0.5, 1, 2]. As verification that three concentrations are necessary, lets also check that removing the intermediate concentration here ([0.25, 4]) also decreases the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eae84c1-33c9-4fda-ad46-56a7dcbceb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Thu Nov 25 22:26:10 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.040115      12531      12531    0.29701          0\n",
      "        500     21.197     1335.2       1330     5.2073          0\n",
      "       1000     42.377     1332.5     1326.9     5.6004          0\n",
      "       1172     49.626     1332.3     1326.6      5.665          0\n",
      "# Successfully finished at Thu Nov 25 22:27:00 2021.\n",
      "# Starting optimization of 5799 parameters at Thu Nov 25 22:27:00 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.044358     1518.7     1453.8      64.91 1.6989e-29\n",
      "        500     26.339     656.49     566.93     59.741     29.822\n",
      "       1000     51.956      585.9     491.87     55.397     38.628\n",
      "       1500     78.126     573.86      480.8     54.441     38.618\n",
      "       1920     99.856     573.31     480.67     53.921      38.72\n",
      "# Successfully finished at Thu Nov 25 22:28:40 2021.\n"
     ]
    }
   ],
   "source": [
    "poly_abs = polyclonal.Polyclonal(data_to_fit=noisy_data.query(f\"concentration in [0.25, 4]\"),\n",
    "                                     activity_wt_df=pd.DataFrame.from_records(\n",
    "                                         [('1', 1.0),\n",
    "                                          ('2', 3.0),\n",
    "                                          ('3', 2.0),\n",
    "                                          ],\n",
    "                                         columns=['epitope', 'activity'],\n",
    "                                         ),\n",
    "                                     site_escape_df=pd.DataFrame.from_records(\n",
    "                                         [('1', 417, 10.0),\n",
    "                                          ('2', 484, 10.0),\n",
    "                                          ('3', 444, 10.0),\n",
    "                                          ],\n",
    "                                         columns=['epitope', 'site', 'escape'],\n",
    "                                         ),\n",
    "                                     data_mut_escape_overlap='fill_to_data',\n",
    "                                 )\n",
    "    \n",
    "opt_res = poly_abs.fit(logfreq=500)\n",
    "pickle.dump(poly_abs, open(f'scipy_results/conc_exp2_noisy_2wointermediate_expanded_conc_3muts.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e790777-f033-45ba-8519-0714c8c690f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epitope</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class 1</td>\n",
       "      <td>0.845842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class 2</td>\n",
       "      <td>0.971332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class 3</td>\n",
       "      <td>0.941974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epitope  correlation\n",
       "0  class 1     0.845842\n",
       "1  class 2     0.971332\n",
       "2  class 3     0.941974"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pickle.load(open(f'scipy_results/conc_exp2_noisy_2wointermediate_expanded_conc_3muts.pkl', 'rb'))\n",
    "\n",
    "mut_escape_pred = (\n",
    "        pd.read_csv('RBD_mut_escape_df.csv')\n",
    "        .merge((model.mut_escape_df\n",
    "                .assign(epitope=lambda x: 'class ' + x['epitope'].astype(str))\n",
    "                .rename(columns={'escape': 'predicted escape'})\n",
    "                ),\n",
    "               on=['mutation', 'epitope'],\n",
    "               validate='one_to_one',\n",
    "               )\n",
    "        )\n",
    "\n",
    "corr = (mut_escape_pred\n",
    "        .groupby('epitope')\n",
    "        .apply(lambda x: x['escape'].corr(x['predicted escape']))\n",
    "        .rename('correlation')\n",
    "        .reset_index()\n",
    "        )\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1142ecce-dfdd-4a87-b6e0-7d6a820983f4",
   "metadata": {},
   "source": [
    "Yes, it mostly affected the correlation for epitope 1, similar to what we observed previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b903f967-5af5-4f21-90ca-5a6260528c52",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6b57efa-743c-46da-b3a8-bebeff9470bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epitope</th>\n",
       "      <th>correlation</th>\n",
       "      <th>num_concentrations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class 1</td>\n",
       "      <td>0.832552</td>\n",
       "      <td>[0.5, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class 2</td>\n",
       "      <td>0.967225</td>\n",
       "      <td>[0.5, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class 3</td>\n",
       "      <td>0.932690</td>\n",
       "      <td>[0.5, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class 1</td>\n",
       "      <td>0.845842</td>\n",
       "      <td>[0.25, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class 2</td>\n",
       "      <td>0.971332</td>\n",
       "      <td>[0.25, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epitope  correlation num_concentrations\n",
       "0  class 1     0.832552           [0.5, 2]\n",
       "1  class 2     0.967225           [0.5, 2]\n",
       "2  class 3     0.932690           [0.5, 2]\n",
       "0  class 1     0.845842          [0.25, 4]\n",
       "1  class 2     0.971332          [0.25, 4]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_models = ['conc_exp2_noisy_2wointermediate_conc_3muts.pkl',\n",
    "               'conc_exp2_noisy_2wointermediate_expanded_conc_3muts.pkl',\n",
    "               'conc_exp2_noisy_3conc_3muts.pkl',\n",
    "               'noisy_3conc_3muts.pkl',\n",
    "               'conc_exp1_noisy_6conc_3muts.pkl']\n",
    "\n",
    "model_names = ['[0.5, 2]', '[0.25, 4]', '[0.5, 1, 2]', '[0.25, 1, 4]', '[0.125, 0.25, 0.5, 1, 2, 4]']\n",
    "\n",
    "all_corrs = pd.DataFrame({'epitope' : [], \n",
    "                          'correlation' : [], \n",
    "                          'num_concentrations' : []}\n",
    "                        )\n",
    "\n",
    "for model,name in zip(good_models, model_names):\n",
    "    model = pickle.load(open(f'scipy_results/{model}', 'rb'))\n",
    "\n",
    "    mut_escape_pred = (\n",
    "        pd.read_csv('RBD_mut_escape_df.csv')\n",
    "        .merge((model.mut_escape_df\n",
    "                .assign(epitope=lambda x: 'class ' + x['epitope'].astype(str))\n",
    "                .rename(columns={'escape': 'predicted escape'})\n",
    "                ),\n",
    "               on=['mutation', 'epitope'],\n",
    "               validate='one_to_one',\n",
    "               )\n",
    "        )\n",
    "\n",
    "    corr = (mut_escape_pred\n",
    "            .groupby('epitope')\n",
    "            .apply(lambda x: x['escape'].corr(x['predicted escape']))\n",
    "            .rename('correlation')\n",
    "            .reset_index()\n",
    "            )\n",
    "    all_corrs = pd.concat([all_corrs, \n",
    "                           corr.assign(num_concentrations = [name] * len(corr.index))]\n",
    "                         )\n",
    "all_corrs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7700a5e4-2194-4549-829d-0da094132846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-dcb1e250076c414fb005b6a5362c83d3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-dcb1e250076c414fb005b6a5362c83d3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-dcb1e250076c414fb005b6a5362c83d3\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-7631e8d818c0896b56bea1aca47060e6\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"num_concentrations\", \"sort\": {\"field\": \"color\", \"order\": \"descending\"}, \"type\": \"nominal\"}, \"column\": {\"field\": \"epitope\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"num_concentrations\", \"type\": \"nominal\"}, {\"field\": \"correlation\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"labels\": false}, \"field\": \"num_concentrations\", \"sort\": {\"field\": \"x\", \"order\": \"descending\"}, \"type\": \"ordinal\"}, \"y\": {\"field\": \"correlation\", \"type\": \"quantitative\"}}, \"height\": 200, \"width\": 125, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-7631e8d818c0896b56bea1aca47060e6\": [{\"epitope\": \"class 1\", \"correlation\": 0.8325522654940898, \"num_concentrations\": \"[0.5, 2]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9672245684943018, \"num_concentrations\": \"[0.5, 2]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.932690019139765, \"num_concentrations\": \"[0.5, 2]\"}, {\"epitope\": \"class 1\", \"correlation\": 0.845842106617216, \"num_concentrations\": \"[0.25, 4]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9713320188617977, \"num_concentrations\": \"[0.25, 4]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.9419738348610237, \"num_concentrations\": \"[0.25, 4]\"}, {\"epitope\": \"class 1\", \"correlation\": 0.8725033873875513, \"num_concentrations\": \"[0.5, 1, 2]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9683628090186779, \"num_concentrations\": \"[0.5, 1, 2]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.9462361627854732, \"num_concentrations\": \"[0.5, 1, 2]\"}, {\"epitope\": \"class 1\", \"correlation\": 0.8828352439294088, \"num_concentrations\": \"[0.25, 1, 4]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9729747874088035, \"num_concentrations\": \"[0.25, 1, 4]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.94969585001127, \"num_concentrations\": \"[0.25, 1, 4]\"}, {\"epitope\": \"class 1\", \"correlation\": 0.8756581891681191, \"num_concentrations\": \"[0.125, 0.25, 0.5, 1, 2, 4]\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9763535533863456, \"num_concentrations\": \"[0.125, 0.25, 0.5, 1, 2, 4]\"}, {\"epitope\": \"class 3\", \"correlation\": 0.9543748495394667, \"num_concentrations\": \"[0.125, 0.25, 0.5, 1, 2, 4]\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(all_corrs).mark_bar().encode(\n",
    "    x= alt.X('num_concentrations:O', axis=alt.Axis(labels=False), sort=alt.EncodingSortField('x', order='descending')),\n",
    "    y='correlation:Q',\n",
    "    color=alt.Color('num_concentrations:N', sort=alt.EncodingSortField('color', order='descending')),\n",
    "    column='epitope:N',\n",
    "    tooltip = ['num_concentrations', 'correlation']\n",
    ").properties(width=125, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c737b22-1c2f-480e-a36c-cc5ceefa8d40",
   "metadata": {},
   "source": [
    "[0.25, 1, 4] is a good concentration set to use. However, two concentrations could also work fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22becaa6-0118-4406-9373-90d75edee1b5",
   "metadata": {},
   "source": [
    "## What makes this concentration set optimal?\n",
    "\n",
    "Is there something special about the predicted IC50's of variants under these conditions that makes it most suitable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f24e9a6-c7e1-4a5e-bf68-539c6d064eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
