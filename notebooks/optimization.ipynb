{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee2a908-c776-4836-9acf-81b001a1ab69",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "We use a scaled [Pseudo-Huber](https://en.wikipedia.org/wiki/Huber_loss#Pseudo-Huber_loss_function) loss function on the difference between the predicted and measure escape proabilities.\n",
    "Note that the Pseudo-Huber function is defined as $\\hat{h}_{\\delta}\\left(x\\right) = \\delta^2 \\left(\\sqrt{1 + \\left(x/\\delta\\right)^2} - 1\\right)$ where $\\delta$ is a parameter that indicates when the loss transitions from being quadratic (L2-like) to linear (L1-like) in $a$.\n",
    "Note that we will actually use a scaled Pseudo-Huber function of $h_{\\delta}\\left(x\\right) = \\hat{h}_{\\delta}\\left(x\\right)/\\delta$ so the slope of the loss is one in the linear range.\n",
    "The rationale for a Pseudo-Huber loss is to be robust to outliers (L1-like for large residuals).\n",
    "\n",
    "Specifically, let $r_v\\left(c\\right) = p_v\\left(c\\right) - y_{v,c}$ be the residual for the predicted of the escape probability of variant $v$ at concentration $c$, where we are using $y_{v,c}$ to denote the measured value.\n",
    "Then the loss for variant $v$ at concentration $c$ is $L_{\\delta_{\\rm{loss}}}\\left(r_v\\left(c\\right)\\right) = h_{\\delta_{\\rm{loss}}}\\left(r_v\\left(c\\right)\\right)$, and the overall loss is:\n",
    "$$ L = \\sum_{v,c} h_{\\delta_{\\rm{loss}}}\\left(r_v\\left(c\\right)\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b03b88-b067-4c15-aafa-0b35b52a5ff1",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "We also regularize the $\\beta_{m,e}$ values based on the notions:\n",
    "\n",
    " 1. Most mutations should not mediate escape,\n",
    " 2. When a site is involved in escape for a given epitope, most mutations at a site will have similar-ish effects.\n",
    "\n",
    "### Regularization of escape values \n",
    "We regularize the escape values $\\beta_{m,e}$ using a simple Pseudo-Huber function, so that\n",
    "$$R_{\\rm{escape}} = \\lambda_{\\rm{escape}} \\sum_{m,e} h_{\\delta_{\\rm{escape}}}\\left(\\beta_{m,e}\\right)$$\n",
    "where $\\lambda_{\\rm{escape}}$ is the strength of the regularization and $\\delta_{\\rm{escape}}$ is the Psdeuo-Huber delta parameter.\n",
    "\n",
    "### Regularization of spread of escape values at each site and epitope\n",
    "We regularize the variance of the escape values at each site, so that\n",
    "$$R_{\\rm{spread}} = \\lambda_{\\rm{spread}} \\sum_{e,i} \\frac{1}{M_i}\\sum_{m \\in i}\\left(\\beta_{m,e} - \\frac{1}{M_i} \\sum_{m' \\in i} \\beta_{m',e}\\right)^2$$\n",
    "where $i$ ranges over all sites, $M_i$ is the number of mutations at site $i$, and $m \\in i$ indicates all mutations at site $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e0904-7d92-4996-a588-f957192311e9",
   "metadata": {},
   "source": [
    "## Gradients used for optimization\n",
    "\n",
    "### Gradient of loss function\n",
    "For the loss function, the gradients are as follows:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\beta_{m,e}} =\n",
    "\\sum_{v,c}\n",
    "\\frac{r_v\\left(c\\right)}{h_{\\delta}\\left(r_v\\left(c\\right)\\right) + \\delta}\n",
    "p_v\\left(c\\right) \\left[1 - U_e\\left(v, c\\right)\\right] b\\left(v\\right)_m\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial a_{\\rm{wt},e}} =\n",
    "-\\sum_{v,c}\n",
    "\\frac{r_v\\left(c\\right)}{h_{\\delta}\\left(r_v\\left(c\\right)\\right) + \\delta}\n",
    "p_v\\left(c\\right) \\left[1 - U_e\\left(v, c\\right)\\right]\n",
    "$$\n",
    "\n",
    "See below for how the sub-components that lead to these were calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8027e394-8ea5-4db9-8f92-a4a52d74313d",
   "metadata": {},
   "source": [
    "#### Calculating $\\frac{\\partial \\left[h_{\\delta}\\left(r\\right)\\right]}{\\partial r}$\n",
    "\n",
    "We have\n",
    "$$ \\frac{\\partial \\left[h_{\\delta}\\left(r\\right)\\right]}{\\partial r}\n",
    "= \\delta \\frac{\\partial \\left(\\sqrt{1 + \\left(r/\\delta\\right)^2} - 1\\right)}{\\partial r}\n",
    "= \\frac{\\delta}{2 \\sqrt{1 + \\left(r/\\delta\\right)^2}} \\frac{2r}{\\delta^2}\n",
    "= \\frac{r}{h_{\\delta}\\left(r\\right) + \\delta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a540a53a-ea1d-47f0-bdb0-9ed8221c0ad8",
   "metadata": {},
   "source": [
    "#### Calculating $\\frac{\\partial p_v\\left(c\\right)}{\\partial \\beta_{m,e}}$\n",
    "\n",
    "First, note \n",
    "\n",
    "$$\n",
    "\\frac{\\partial p_v\\left(c\\right)}{\\partial \\beta_{m,e}} = \\frac{\\partial U_e\\left(v, c\\right)}{\\partial \\beta_{m,e}} \\frac{p_v\\left(c\\right)}{U_e\\left(v, c\\right)}.\n",
    "$$\n",
    "\n",
    "\n",
    "Next, note\n",
    "$$\n",
    "\\frac{\\partial U_e\\left(v, c\\right)}{\\partial \\beta_{m,e}} = \\frac{\\partial \\phi_e\\left(v\\right)}{\\partial \\beta_{m,e}}\\frac{c \\exp\\left(-\\phi_e\\left(v\\right)\\right) }{\\left[1 + c \\exp\\left(-\\phi_e\\left(v\\right)\\right)\\right]^2} = \\frac{\\partial \\phi_e\\left(v\\right)}{\\partial \\beta_{m,e}} U_e\\left(v, c\\right) \\left[1 - U_e\\left(v, c\\right)\\right]\n",
    "$$\n",
    "where the last step uses the simplification [here](https://math.stackexchange.com/a/1225116).\n",
    "\n",
    "Finally, note\n",
    "$$\\frac{\\partial \\phi_e\\left(v\\right)}{\\partial \\beta_{m,e}} = b\\left(v\\right)_m.$$\n",
    "\n",
    "Putting it all together, we have:\n",
    "$$\n",
    "\\frac{\\partial p_v\\left(c\\right)}{\\partial \\beta_{m,e}} = p_v\\left(c\\right) \\left[1 - U_e\\left(v, c\\right)\\right] b\\left(v\\right)_m.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4f494-0764-44e8-ab25-753b5e9c7ac6",
   "metadata": {},
   "source": [
    "#### Calculating $\\frac{\\partial p_v\\left(c\\right)}{\\partial a_{\\rm{wt},e}}$\n",
    "The only difference from above is the sign, so:\n",
    "$$\n",
    "\\frac{\\partial p_v\\left(c\\right)}{\\partial a_{\\rm{wt},e}} = -p_v\\left(c\\right) \\left[1 - U_e\\left(v, c\\right)\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de0e16c-de3b-499e-8171-329804414755",
   "metadata": {},
   "source": [
    "### Gradients of regularizations\n",
    "\n",
    "#### Calculating $\\frac{\\partial R_{\\rm{site\\, escape}}}{\\partial \\beta_{m,e}}$\n",
    "\n",
    "$$\\frac{\\partial R_{\\rm{site\\, escape}}}{\\partial \\beta_{m,e}} = \\frac{\\lambda_{\\rm{escape}}\\beta_{m,e}}{h_{\\delta_{\\rm{escape}}}\\left(\\beta_{m,e}\\right) + \\delta_{\\rm{escape}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c9e3ab-505d-4fc3-9f66-11e064e031f7",
   "metadata": {},
   "source": [
    "#### Calculating $\\frac{\\partial R_{\\rm{spread}}}{\\partial \\beta_{m,e}}$\n",
    "$$\\frac{\\partial R_{\\rm{spread}}}{\\partial \\beta_{m,e}} = \\frac{2\\lambda_{\\rm{spread}}}{M_i} \\left(\\beta_{m,e} - \\frac{1}{M_i} \\sum_{m' \\in i} \\beta_{m',e}\\right)\\frac{M_i - 1}{M_i}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
