{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What mutation rate should we use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have simulated noisy data with average of 1, 2, 3, and 4 mutations. If we fit a model to each of them, how good are the fits? \n",
    "Each library has 30,000 variants and we will use the same parameters in each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polyclonal\n",
    "import pickle\n",
    "import random\n",
    "import altair as alt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>library</th>\n",
       "      <th>aa_substitutions</th>\n",
       "      <th>concentration</th>\n",
       "      <th>prob_escape</th>\n",
       "      <th>IC90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg1muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.087480</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg1muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.034240</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg1muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.037880</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg1muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.035730</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg1muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359995</th>\n",
       "      <td>avg2muts</td>\n",
       "      <td>Y473E L518F D427L</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>1.1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359996</th>\n",
       "      <td>avg1muts</td>\n",
       "      <td>Y473S G413Q</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359997</th>\n",
       "      <td>avg1muts</td>\n",
       "      <td>Y473V P479R F392W</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>1.4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359998</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td>Y489Q N501Y</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359999</th>\n",
       "      <td>avg2muts</td>\n",
       "      <td>Y505N H519T</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         library   aa_substitutions  concentration  prob_escape    IC90\n",
       "0       avg1muts                              0.25     0.087480  0.1128\n",
       "1       avg1muts                              0.25     0.034240  0.1128\n",
       "2       avg1muts                              0.25     0.037880  0.1128\n",
       "3       avg1muts                              0.25     0.035730  0.1128\n",
       "4       avg1muts                              0.25     0.000000  0.1128\n",
       "...          ...                ...            ...          ...     ...\n",
       "359995  avg2muts  Y473E L518F D427L           4.00     0.002918  1.1600\n",
       "359996  avg1muts        Y473S G413Q           4.00     0.000000  0.5780\n",
       "359997  avg1muts  Y473V P479R F392W           4.00     0.160200  1.4550\n",
       "359998  avg3muts        Y489Q N501Y           4.00     0.000000  0.5881\n",
       "359999  avg2muts        Y505N H519T           4.00     0.000000  0.3505\n",
       "\n",
       "[360000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_data = (\n",
    "    pd.read_csv('RBD_variants_escape_noisy.csv', na_filter=None)\n",
    "    .query('concentration in [0.25, 1, 4]')\n",
    "    .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "noisy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polyclonal model simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Wed Nov 24 12:15:19 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.019013     2659.6     2659.3    0.29701          0\n",
      "        500     10.095      450.7     445.11     5.5853          0\n",
      "       1000     19.934     446.89     440.67     6.2131          0\n",
      "       1500     30.185     445.25     438.71     6.5333          0\n",
      "       1633     32.894     445.15     438.58      6.571          0\n",
      "# Successfully finished at Wed Nov 24 12:15:52 2021.\n",
      "# Starting optimization of 5796 parameters at Wed Nov 24 12:15:52 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.024132      785.7     705.71      79.99  1.819e-29\n",
      "        500     13.547     397.01     326.36     52.328     18.324\n",
      "       1000     27.127      379.6     318.79     38.518     22.295\n",
      "       1500     40.875     375.65     316.88     35.772         23\n",
      "       1782     48.548     375.08     316.19     35.691     23.198\n",
      "# Successfully finished at Wed Nov 24 12:16:41 2021.\n",
      "Model fit on library with 1 mutation per variant on average written to scipy_results/noisy_3conc_1muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Wed Nov 24 12:16:42 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.041536     9144.4     9144.2    0.29701          0\n",
      "        500     22.916     1297.9     1291.8     6.0834          0\n",
      "       1000     45.241     1295.4     1288.4     7.0221          0\n",
      "       1152      51.89     1294.9     1287.8     7.0623          0\n",
      "# Successfully finished at Wed Nov 24 12:17:34 2021.\n",
      "# Starting optimization of 5799 parameters at Wed Nov 24 12:17:34 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0    0.04758     1640.1     1552.3     87.755 2.1395e-29\n",
      "        500     26.958     800.65     705.62     75.942     19.095\n",
      "       1000     54.806     764.13      694.1     48.057     21.972\n",
      "       1500     81.969     738.82     665.79     45.532     27.494\n",
      "       2000     109.41      679.1     590.19      51.88      37.03\n",
      "       2500     136.55      665.3     576.43     52.996     35.882\n",
      "       2523     137.76     665.28     576.37     53.031     35.884\n",
      "# Successfully finished at Wed Nov 24 12:19:52 2021.\n",
      "Model fit on library with 2 mutation per variant on average written to scipy_results/noisy_3conc_2muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Wed Nov 24 12:19:54 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.068202      17849      17849    0.29701          0\n",
      "        500     42.818     2134.8     2129.8     4.9739          0\n",
      "       1000     84.787     2129.9     2124.3     5.6121          0\n",
      "       1063     90.355     2129.8     2124.2     5.6365          0\n",
      "# Successfully finished at Wed Nov 24 12:21:24 2021.\n",
      "# Starting optimization of 5799 parameters at Wed Nov 24 12:21:24 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.085437     2363.3     2299.2     64.167 1.3252e-29\n",
      "        500     49.015     991.34     895.79     62.575     32.971\n",
      "       1000     96.795     900.17     801.29     58.581     40.305\n",
      "       1500     145.38     869.75     772.68     56.219     40.856\n",
      "       2000      193.7     857.33     761.59     55.191     40.548\n",
      "       2420     232.98     856.59      761.5     54.451     40.633\n",
      "# Successfully finished at Wed Nov 24 12:25:17 2021.\n",
      "Model fit on library with 3 mutation per variant on average written to scipy_results/noisy_3conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Wed Nov 24 12:25:20 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.098744      27747      27746    0.29701          0\n",
      "        500     52.384     2650.3     2645.3     4.9904          0\n",
      "        516     53.883     2650.3     2645.3     4.9927          0\n",
      "# Successfully finished at Wed Nov 24 12:26:14 2021.\n",
      "# Starting optimization of 5799 parameters at Wed Nov 24 12:26:14 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.099156     2795.9     2738.6     57.294 1.0074e-29\n",
      "        500     61.316     990.79     890.81     59.094      40.89\n",
      "       1000      122.7     977.22     878.58     57.262     41.378\n",
      "       1500     184.96     972.86     874.99     56.117     41.753\n",
      "       1818     222.65      972.3     875.24      55.52     41.542\n",
      "# Successfully finished at Wed Nov 24 12:29:56 2021.\n",
      "Model fit on library with 4 mutation per variant on average written to scipy_results/noisy_3conc_4muts.pkl\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "for n in [1,2,3,4]:\n",
    "    poly_abs = polyclonal.Polyclonal(data_to_fit=noisy_data.query(f\"library == 'avg{n}muts'\"),\n",
    "                                     activity_wt_df=pd.DataFrame.from_records(\n",
    "                                         [('1', 1.0),\n",
    "                                          ('2', 3.0),\n",
    "                                          ('3', 2.0),\n",
    "                                          ],\n",
    "                                         columns=['epitope', 'activity'],\n",
    "                                         ),\n",
    "                                     site_escape_df=pd.DataFrame.from_records(\n",
    "                                         [('1', 417, 10.0),\n",
    "                                          ('2', 484, 10.0),\n",
    "                                          ('3', 444, 10.0),\n",
    "                                          ],\n",
    "                                         columns=['epitope', 'site', 'escape'],\n",
    "                                         ),\n",
    "                                     data_mut_escape_overlap='fill_to_data',\n",
    "                                 )\n",
    "    \n",
    "    opt_res = poly_abs.fit(logfreq=500)\n",
    "    pickle.dump(poly_abs, open(f'scipy_results/noisy_3conc_{n}muts.pkl', 'wb'))\n",
    "    print(f\"Model fit on library with {n} mutation per variant on average written to scipy_results/noisy_3conc_{n}muts.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get correlation between predicted and true beta coefficients for each trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epitope</th>\n",
       "      <th>correlation</th>\n",
       "      <th>library</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class 1</td>\n",
       "      <td>0.127960</td>\n",
       "      <td>avg1muts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class 2</td>\n",
       "      <td>0.857029</td>\n",
       "      <td>avg1muts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class 3</td>\n",
       "      <td>0.653858</td>\n",
       "      <td>avg1muts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class 1</td>\n",
       "      <td>0.812462</td>\n",
       "      <td>avg2muts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class 2</td>\n",
       "      <td>0.956589</td>\n",
       "      <td>avg2muts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epitope  correlation   library\n",
       "0  class 1     0.127960  avg1muts\n",
       "1  class 2     0.857029  avg1muts\n",
       "2  class 3     0.653858  avg1muts\n",
       "0  class 1     0.812462  avg2muts\n",
       "1  class 2     0.956589  avg2muts"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_corrs = pd.DataFrame({'epitope' : [], \n",
    "                          'correlation' : [], \n",
    "                          'library' : []}\n",
    "                        )\n",
    "\n",
    "for n in [1,2,3,4]:\n",
    "    model = pickle.load(open(f'scipy_results/noisy_3conc_{n}muts.pkl', 'rb'))\n",
    "\n",
    "    mut_escape_pred = (\n",
    "        pd.read_csv('RBD_mut_escape_df.csv')\n",
    "        .merge((model.mut_escape_df\n",
    "                .assign(epitope=lambda x: 'class ' + x['epitope'].astype(str))\n",
    "                .rename(columns={'escape': 'predicted escape'})\n",
    "                ),\n",
    "               on=['mutation', 'epitope'],\n",
    "               validate='one_to_one',\n",
    "               )\n",
    "        )\n",
    "\n",
    "    corr = (mut_escape_pred\n",
    "            .groupby('epitope')\n",
    "            .apply(lambda x: x['escape'].corr(x['predicted escape']))\n",
    "            .rename('correlation')\n",
    "            .reset_index()\n",
    "            )\n",
    "    all_corrs = pd.concat([all_corrs, \n",
    "                           corr.assign(library = [f\"avg{n}muts\"] * len(corr.index))]\n",
    "                         )\n",
    "all_corrs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-ed4301e900144c8386aded466099cb74\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ed4301e900144c8386aded466099cb74\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ed4301e900144c8386aded466099cb74\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-4c0e30f2db9d737536d5f1f13e972684\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"library\", \"type\": \"nominal\"}, \"column\": {\"field\": \"epitope\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"library\", \"type\": \"nominal\"}, {\"field\": \"correlation\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"labels\": false}, \"field\": \"library\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"correlation\", \"type\": \"quantitative\"}}, \"height\": 200, \"width\": 125, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-4c0e30f2db9d737536d5f1f13e972684\": [{\"epitope\": \"class 1\", \"correlation\": 0.12796044398108936, \"library\": \"avg1muts\"}, {\"epitope\": \"class 2\", \"correlation\": 0.857028982577385, \"library\": \"avg1muts\"}, {\"epitope\": \"class 3\", \"correlation\": 0.6538580166192145, \"library\": \"avg1muts\"}, {\"epitope\": \"class 1\", \"correlation\": 0.8124616185199585, \"library\": \"avg2muts\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9565890154532138, \"library\": \"avg2muts\"}, {\"epitope\": \"class 3\", \"correlation\": 0.928755819226252, \"library\": \"avg2muts\"}, {\"epitope\": \"class 1\", \"correlation\": 0.8828352439294088, \"library\": \"avg3muts\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9729747874088035, \"library\": \"avg3muts\"}, {\"epitope\": \"class 3\", \"correlation\": 0.94969585001127, \"library\": \"avg3muts\"}, {\"epitope\": \"class 1\", \"correlation\": 0.8896793775467687, \"library\": \"avg4muts\"}, {\"epitope\": \"class 2\", \"correlation\": 0.9693371499510837, \"library\": \"avg4muts\"}, {\"epitope\": \"class 3\", \"correlation\": 0.9592697463846838, \"library\": \"avg4muts\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(all_corrs).mark_bar().encode(\n",
    "    x= alt.X('library:O', axis=alt.Axis(labels=False)),\n",
    "    y='correlation:Q',\n",
    "    color='library:N',\n",
    "    column='epitope:N',\n",
    "    tooltip = ['library', 'correlation']\n",
    ").properties(width=125, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchdms simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>library</th>\n",
       "      <th>aa_substitutions</th>\n",
       "      <th>concentration</th>\n",
       "      <th>prob_escape</th>\n",
       "      <th>IC90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg1muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.025120</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg1muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.025120</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg1muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.025120</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg1muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.025120</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg1muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.025120</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359995</th>\n",
       "      <td>avg4muts</td>\n",
       "      <td>Y508W C525F</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.019370</td>\n",
       "      <td>0.4073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359996</th>\n",
       "      <td>avg4muts</td>\n",
       "      <td>Y508W C525F</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.4073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359997</th>\n",
       "      <td>avg4muts</td>\n",
       "      <td>Y508W G526L</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.197600</td>\n",
       "      <td>0.4122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359998</th>\n",
       "      <td>avg4muts</td>\n",
       "      <td>Y508W G526L</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.4122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359999</th>\n",
       "      <td>avg4muts</td>\n",
       "      <td>Y508W G526L</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.4122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         library aa_substitutions  concentration  prob_escape    IC90\n",
       "0       avg1muts                            0.25     0.025120  0.1128\n",
       "1       avg1muts                            0.25     0.025120  0.1128\n",
       "2       avg1muts                            0.25     0.025120  0.1128\n",
       "3       avg1muts                            0.25     0.025120  0.1128\n",
       "4       avg1muts                            0.25     0.025120  0.1128\n",
       "...          ...              ...            ...          ...     ...\n",
       "359995  avg4muts      Y508W C525F           1.00     0.019370  0.4073\n",
       "359996  avg4muts      Y508W C525F           4.00     0.000655  0.4073\n",
       "359997  avg4muts      Y508W G526L           0.25     0.197600  0.4122\n",
       "359998  avg4muts      Y508W G526L           1.00     0.019800  0.4122\n",
       "359999  avg4muts      Y508W G526L           4.00     0.000672  0.4122\n",
       "\n",
       "[360000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = (\n",
    "    pd.read_csv('RBD_variants_escape_exact.csv', na_filter=None)\n",
    "    .query('concentration in [0.25, 1, 4]')\n",
    "    .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the dataset for each library into separate output directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset written to torchdms_results/noisy_3conc_1muts.\n",
      "Dataset written to torchdms_results/noisy_3conc_2muts.\n",
      "Dataset written to torchdms_results/noisy_3conc_3muts.\n",
      "Dataset written to torchdms_results/noisy_3conc_4muts.\n"
     ]
    }
   ],
   "source": [
    "import torchdms\n",
    "import Bio.SeqIO\n",
    "import pickle\n",
    "\n",
    "wtseq_dna = Bio.SeqIO.read('RBD_seq.fasta', 'fasta').seq\n",
    "wtseq_aa = str(wtseq_dna.translate())\n",
    "assert len(wtseq_aa) == 201\n",
    "\n",
    "for n in [1,2,3,4]:\n",
    "    avg_n_data = noisy_data.query(f\"library == 'avg{n}muts'\")\n",
    "    # torchdms uses 1-indexed mutations\n",
    "    formatted_data = (\n",
    "            avg_n_data\n",
    "            .assign(aa_substitutions=lambda x: x['aa_substitutions'].apply(\n",
    "                                polyclonal.utils.shift_mut_site, shift=-330)\n",
    "            )\n",
    "    )    \n",
    "    assert len(formatted_data.index) == 90000\n",
    "    with open(f\"torchdms_results/noisy_3conc_{n}muts/noisy_3conc_{n}muts_data.pkl\", \"wb\") as f:\n",
    "        pickle.dump([formatted_data, wtseq_aa], f)\n",
    "    print(f\"Dataset written to torchdms_results/noisy_3conc_{n}muts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset written to torchdms_results/clean_3conc_1muts.\n",
      "Dataset written to torchdms_results/clean_3conc_2muts.\n",
      "Dataset written to torchdms_results/clean_3conc_3muts.\n",
      "Dataset written to torchdms_results/clean_3conc_4muts.\n"
     ]
    }
   ],
   "source": [
    "import torchdms\n",
    "import Bio.SeqIO\n",
    "import pickle\n",
    "\n",
    "wtseq_dna = Bio.SeqIO.read('RBD_seq.fasta', 'fasta').seq\n",
    "wtseq_aa = str(wtseq_dna.translate())\n",
    "assert len(wtseq_aa) == 201\n",
    "\n",
    "for n in [1,2,3,4]:\n",
    "    avg_n_data = clean_data.query(f\"library == 'avg{n}muts'\")\n",
    "    # torchdms uses 1-indexed mutations\n",
    "    formatted_data = (\n",
    "            avg_n_data\n",
    "            .assign(aa_substitutions=lambda x: x['aa_substitutions'].apply(\n",
    "                                polyclonal.utils.shift_mut_site, shift=-330)\n",
    "            )\n",
    "    )    \n",
    "    assert len(formatted_data.index) == 90000\n",
    "    with open(f\"torchdms_results/clean_3conc_{n}muts/clean_3conc_{n}muts_data.pkl\", \"wb\") as f:\n",
    "        pickle.dump([formatted_data, wtseq_aa], f)\n",
    "    print(f\"Dataset written to torchdms_results/clean_3conc_{n}muts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the `torchdms` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor n in [1,2,3,4]:\\n    min_test_per_stratum = [200,250,300,350]\\n    min_count_per_stratum = [800,1200,1600,2000]\\n    \\n    %cd torchdms_results/noisy_3conc_{n}muts\\n    \\n    !echo \"Prepping dataset.\"\\n    !tdms prep --per-stratum-variants-for-test {min_test_per_stratum[n-1]} --skip-stratum-if-count-is-smaller-than {min_count_per_stratum[n-1]}     --partition-by library *data.pkl prepped prob_escape\\n    \\n    !echo \"Training model.\"\\n    !tdms go --config config.json\\n\\n    %cd ../.. \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n in [1,2,3,4]:\n",
    "    min_test_per_stratum = [200,250,300,350]\n",
    "    min_count_per_stratum = [800,1200,1600,2000]\n",
    "    \n",
    "    %cd torchdms_results/noisy_3conc_{n}muts\n",
    "    \n",
    "    !echo \"Prepping dataset.\"\n",
    "    !tdms prep --per-stratum-variants-for-test {min_test_per_stratum[n-1]} --skip-stratum-if-count-is-smaller-than {min_count_per_stratum[n-1]} \\\n",
    "    --partition-by library *data.pkl prepped prob_escape\n",
    "    \n",
    "    !echo \"Training model.\"\n",
    "    !tdms go --config config.json\n",
    "\n",
    "    %cd ../.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor n in [1,2,3,4]:\\n    min_test_per_stratum = [200,250,300,350]\\n    min_count_per_stratum = [800,1200,1600,2000]\\n    \\n    %cd torchdms_results/clean_3conc_{n}muts\\n    \\n    !echo \"Prepping dataset.\"\\n    !tdms prep --per-stratum-variants-for-test {min_test_per_stratum[n-1]} --skip-stratum-if-count-is-smaller-than {min_count_per_stratum[n-1]}     --partition-by library *data.pkl prepped prob_escape\\n    \\n    !echo \"Training model.\"\\n    !tdms go --config config.json\\n\\n    %cd ../.. \\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n in [1,2,3,4]:\n",
    "    min_test_per_stratum = [200,250,300,350]\n",
    "    min_count_per_stratum = [800,1200,1600,2000]\n",
    "    \n",
    "    %cd torchdms_results/clean_3conc_{n}muts\n",
    "    \n",
    "    !echo \"Prepping dataset.\"\n",
    "    !tdms prep --per-stratum-variants-for-test {min_test_per_stratum[n-1]} --skip-stratum-if-count-is-smaller-than {min_count_per_stratum[n-1]} \\\n",
    "    --partition-by library *data.pkl prepped prob_escape\n",
    "    \n",
    "    !echo \"Training model.\"\n",
    "    !tdms go --config config.json\n",
    "\n",
    "    %cd ../.. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
