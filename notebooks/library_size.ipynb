{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What library size should we use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test library sizes varying from 1000, 5000, 10000, 200000, 30000 variants to see how these improve model training. We will use a library with 3 mutations on average, and a concentration set = [0.25, 1, 4], which were previously determined to be optimal here and here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polyclonal\n",
    "import pickle\n",
    "import random\n",
    "import altair as alt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>library</th>\n",
       "      <th>aa_substitutions</th>\n",
       "      <th>concentration</th>\n",
       "      <th>prob_escape</th>\n",
       "      <th>IC90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01090</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01458</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.09465</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td>Y449I L518Y C525R L461I</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.02197</td>\n",
       "      <td>2.3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td>Y449V K529R N394R</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.9473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td>Y451L N481T F490V</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.02315</td>\n",
       "      <td>0.9301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td>Y453R V483G L492V N501P I332P</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>avg3muts</td>\n",
       "      <td>Y489Q N501Y</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        library               aa_substitutions  concentration  prob_escape  \\\n",
       "0      avg3muts                                          0.25      0.00000   \n",
       "1      avg3muts                                          0.25      0.01090   \n",
       "2      avg3muts                                          0.25      0.01458   \n",
       "3      avg3muts                                          0.25      0.09465   \n",
       "4      avg3muts                                          0.25      0.03299   \n",
       "...         ...                            ...            ...          ...   \n",
       "89995  avg3muts        Y449I L518Y C525R L461I           4.00      0.02197   \n",
       "89996  avg3muts              Y449V K529R N394R           4.00      0.04925   \n",
       "89997  avg3muts              Y451L N481T F490V           4.00      0.02315   \n",
       "89998  avg3muts  Y453R V483G L492V N501P I332P           4.00      0.00000   \n",
       "89999  avg3muts                    Y489Q N501Y           4.00      0.00000   \n",
       "\n",
       "         IC90  \n",
       "0      0.1128  \n",
       "1      0.1128  \n",
       "2      0.1128  \n",
       "3      0.1128  \n",
       "4      0.1128  \n",
       "...       ...  \n",
       "89995  2.3100  \n",
       "89996  0.9473  \n",
       "89997  0.9301  \n",
       "89998  5.0120  \n",
       "89999  0.5881  \n",
       "\n",
       "[90000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_data = (\n",
    "    pd.read_csv('RBD_variants_escape_noisy.csv', na_filter=None)\n",
    "    .query(\"library == 'avg3muts'\")\n",
    "    .query('concentration in [0.25, 1, 4]')\n",
    "    .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# First fitting site-level model.\n",
      "# Starting optimization of 519 parameters at Fri Nov 26 11:41:39 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.011101     609.84     609.54    0.29701          0\n",
      "        500     5.3137     56.556     51.293     5.2629          0\n",
      "       1000     10.359     55.669     50.234     5.4356          0\n",
      "       1239     12.641     55.516      50.03     5.4861          0\n",
      "# Successfully finished at Fri Nov 26 11:41:52 2021.\n",
      "# Starting optimization of 5448 parameters at Fri Nov 26 11:41:52 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.010517     112.21     51.685     60.526 1.4313e-29\n",
      "        500     6.2786     36.836     13.726     16.696      6.414\n",
      "        776     9.6045     36.248     14.414     15.558     6.2759\n",
      "# Successfully finished at Fri Nov 26 11:42:02 2021.\n",
      "Model fit on library with 1000 variants to scipy_results/libsize1000_noisy_3conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Fri Nov 26 11:42:02 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.019288     3011.7     3011.5    0.29701          0\n",
      "        500     9.1369     357.12      351.5     5.6144          0\n",
      "       1000     17.778      356.5     350.33     6.1657          0\n",
      "       1006     17.855      356.5     350.33      6.168          0\n",
      "# Successfully finished at Fri Nov 26 11:42:20 2021.\n",
      "# Starting optimization of 5799 parameters at Fri Nov 26 11:42:20 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.019165     438.83     367.63     71.203 1.1274e-29\n",
      "        500      10.02     168.75     105.71     42.829      20.21\n",
      "       1000     19.921     161.91     97.066      41.93     22.913\n",
      "       1500     29.812     160.25     92.744     43.283      24.22\n",
      "       2000     39.058      159.3      90.43     44.069     24.797\n",
      "       2175     42.293     159.24      90.36       44.1     24.784\n",
      "# Successfully finished at Fri Nov 26 11:43:02 2021.\n",
      "Model fit on library with 5000 variants to scipy_results/libsize5000_noisy_3conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Fri Nov 26 11:43:03 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.027148       6010     6009.8    0.29701          0\n",
      "        500     13.905     715.35     709.94     5.4106          0\n",
      "       1000     26.889     714.08      708.4      5.678          0\n",
      "       1092     29.248     713.97     708.24     5.7294          0\n",
      "# Successfully finished at Fri Nov 26 11:43:33 2021.\n",
      "# Starting optimization of 5799 parameters at Fri Nov 26 11:43:33 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.027581     818.04     750.91     67.133 1.3458e-29\n",
      "        500     20.314      345.6     270.43     53.507     21.659\n",
      "       1000     35.809     307.43      227.9     50.521     29.011\n",
      "       1387     47.601     300.85     220.69     50.368     29.791\n",
      "# Successfully finished at Fri Nov 26 11:44:20 2021.\n",
      "Model fit on library with 10000 variants to scipy_results/libsize10000_noisy_3conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Fri Nov 26 11:44:22 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.047802      11883      11883    0.29701          0\n",
      "        500     23.866     1431.4     1426.1     5.3127          0\n",
      "       1000     47.371     1425.6       1419     6.5737          0\n",
      "       1500     69.978     1424.5     1417.6     6.9633          0\n",
      "       2000     92.447     1423.6     1416.2      7.407          0\n",
      "       2084     96.429     1423.5     1416.1     7.4498          0\n",
      "# Successfully finished at Fri Nov 26 11:45:58 2021.\n",
      "# Starting optimization of 5799 parameters at Fri Nov 26 11:45:58 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.047103       1604     1517.3     86.656 2.5845e-29\n",
      "        500     26.932     767.67      677.5     72.708     17.462\n",
      "       1000     53.304     731.94     661.19     50.585     20.172\n",
      "       1500     79.503     697.85     624.37     48.025     25.455\n",
      "       2000      105.3     599.29     509.04     53.062     37.196\n",
      "       2500     131.52     585.75     496.74      52.78     36.227\n",
      "       2508     131.94     585.75     496.74      52.78     36.227\n",
      "# Successfully finished at Fri Nov 26 11:48:10 2021.\n",
      "Model fit on library with 20000 variants to scipy_results/libsize20000_noisy_3conc_3muts.pkl\n",
      "# First fitting site-level model.\n",
      "# Starting optimization of 522 parameters at Fri Nov 26 11:48:12 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.065797      17849      17849    0.29701          0\n",
      "        500     40.504     2132.8     2127.8     5.0296          0\n",
      "       1000     79.407     2129.4     2123.9     5.5734          0\n",
      "       1255     99.266       2129     2123.3     5.6361          0\n",
      "# Successfully finished at Fri Nov 26 11:49:51 2021.\n",
      "# Starting optimization of 5799 parameters at Fri Nov 26 11:49:51 2021.\n",
      "       step   time_sec       loss   fit_loss reg_escape  regspread\n",
      "          0   0.085115     2361.2     2298.2     62.958 1.0503e-29\n",
      "        500     49.789     979.63        883     62.111     34.516\n",
      "       1000     107.23      895.5     797.07     57.923     40.504\n",
      "       1500     162.34     876.44     779.15      56.14     41.151\n",
      "       2000     219.49     857.17      761.6     54.787     40.779\n",
      "       2470     266.16     856.39     761.54     54.201     40.648\n",
      "# Successfully finished at Fri Nov 26 11:54:18 2021.\n",
      "Model fit on library with 30000 variants to scipy_results/libsize30000_noisy_3conc_3muts.pkl\n"
     ]
    }
   ],
   "source": [
    "library_sizes = [1000, 5000, 10000, 20000, 30000]\n",
    "\n",
    "for size in library_sizes:\n",
    "    poly_abs = polyclonal.Polyclonal(data_to_fit=(noisy_data.groupby('concentration')\n",
    "                                                            .apply(lambda x: x.sample(n=size, random_state=123))\n",
    "                                                            .reset_index(drop = True)),\n",
    "                                     activity_wt_df=pd.DataFrame.from_records(\n",
    "                                         [('1', 1.0),\n",
    "                                          ('2', 3.0),\n",
    "                                          ('3', 2.0),\n",
    "                                          ],\n",
    "                                         columns=['epitope', 'activity'],\n",
    "                                         ),\n",
    "                                     site_escape_df=pd.DataFrame.from_records(\n",
    "                                         [('1', 417, 10.0),\n",
    "                                          ('2', 484, 10.0),\n",
    "                                          ('3', 444, 10.0),\n",
    "                                          ],\n",
    "                                         columns=['epitope', 'site', 'escape'],\n",
    "                                         ),\n",
    "                                     data_mut_escape_overlap='fill_to_data',\n",
    "                                 )\n",
    "    \n",
    "    opt_res = poly_abs.fit(logfreq=500)\n",
    "    pickle.dump(poly_abs, open(f'scipy_results/libsize{size}_noisy_3conc_3muts.pkl', 'wb'))\n",
    "    print(f\"Model fit on library with {size} variants to scipy_results/libsize{size}_noisy_3conc_3muts.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get correlation between predicted and true beta coefficients for each trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epitope</th>\n",
       "      <th>correlation</th>\n",
       "      <th>num_variants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class 1</td>\n",
       "      <td>0.024152</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class 2</td>\n",
       "      <td>0.619466</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class 3</td>\n",
       "      <td>0.142082</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class 1</td>\n",
       "      <td>0.231682</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class 2</td>\n",
       "      <td>0.809985</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epitope  correlation  num_variants\n",
       "0  class 1     0.024152        1000.0\n",
       "1  class 2     0.619466        1000.0\n",
       "2  class 3     0.142082        1000.0\n",
       "0  class 1     0.231682        5000.0\n",
       "1  class 2     0.809985        5000.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library_sizes = [1000, 5000, 10000, 20000, 30000]\n",
    "all_corrs = pd.DataFrame({'epitope' : [], \n",
    "                          'correlation' : [], \n",
    "                          'num_variants' : []}\n",
    "                        )\n",
    "\n",
    "for size in library_sizes:\n",
    "    model = pickle.load(open(f'scipy_results/libsize{size}_noisy_3conc_3muts.pkl', 'rb'))\n",
    "\n",
    "    mut_escape_pred = (\n",
    "        pd.read_csv('RBD_mut_escape_df.csv')\n",
    "        .merge((model.mut_escape_df\n",
    "                .assign(epitope=lambda x: 'class ' + x['epitope'].astype(str))\n",
    "                .rename(columns={'escape': 'predicted escape'})\n",
    "                ),\n",
    "               on=['mutation', 'epitope'],\n",
    "               validate='one_to_one',\n",
    "               )\n",
    "        )\n",
    "\n",
    "    corr = (mut_escape_pred\n",
    "            .groupby('epitope')\n",
    "            .apply(lambda x: x['escape'].corr(x['predicted escape']))\n",
    "            .rename('correlation')\n",
    "            .reset_index()\n",
    "            )\n",
    "    all_corrs = pd.concat([all_corrs, \n",
    "                           corr.assign(num_variants = [size] * len(corr.index))]\n",
    "                         )\n",
    "all_corrs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-9b47f8e1733e4134b93eb9597e6e8879\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9b47f8e1733e4134b93eb9597e6e8879\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9b47f8e1733e4134b93eb9597e6e8879\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": \"point\", \"encoding\": {\"color\": {\"field\": \"epitope\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"num_variants\", \"type\": \"quantitative\"}, {\"field\": \"correlation\", \"type\": \"quantitative\"}, {\"field\": \"epitope\", \"type\": \"nominal\"}], \"x\": {\"field\": \"num_variants\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"correlation\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"line\", \"size\": 2.5}, \"encoding\": {\"color\": {\"field\": \"epitope\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"num_variants\", \"type\": \"quantitative\"}, {\"field\": \"correlation\", \"type\": \"quantitative\"}, {\"field\": \"epitope\", \"type\": \"nominal\"}], \"x\": {\"field\": \"num_variants\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"correlation\", \"type\": \"quantitative\"}}, \"transform\": [{\"loess\": \"correlation\", \"on\": \"num_variants\", \"groupby\": [\"epitope\"]}]}], \"data\": {\"name\": \"data-08409d4e8568b8ecccf762bdd614cc12\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-08409d4e8568b8ecccf762bdd614cc12\": [{\"epitope\": \"class 1\", \"correlation\": 0.0241523798559658, \"num_variants\": 1000.0}, {\"epitope\": \"class 2\", \"correlation\": 0.6194656714239446, \"num_variants\": 1000.0}, {\"epitope\": \"class 3\", \"correlation\": 0.14208162210170724, \"num_variants\": 1000.0}, {\"epitope\": \"class 1\", \"correlation\": 0.23168196636972116, \"num_variants\": 5000.0}, {\"epitope\": \"class 2\", \"correlation\": 0.8099853337682328, \"num_variants\": 5000.0}, {\"epitope\": \"class 3\", \"correlation\": 0.6779346673176389, \"num_variants\": 5000.0}, {\"epitope\": \"class 1\", \"correlation\": 0.7582495642268794, \"num_variants\": 10000.0}, {\"epitope\": \"class 2\", \"correlation\": 0.9308485198950717, \"num_variants\": 10000.0}, {\"epitope\": \"class 3\", \"correlation\": 0.8915241645696071, \"num_variants\": 10000.0}, {\"epitope\": \"class 1\", \"correlation\": 0.8298801310531777, \"num_variants\": 20000.0}, {\"epitope\": \"class 2\", \"correlation\": 0.9659975232864269, \"num_variants\": 20000.0}, {\"epitope\": \"class 3\", \"correlation\": 0.9364289344892847, \"num_variants\": 20000.0}, {\"epitope\": \"class 1\", \"correlation\": 0.8693502104813184, \"num_variants\": 30000.0}, {\"epitope\": \"class 2\", \"correlation\": 0.9729132281737594, \"num_variants\": 30000.0}, {\"epitope\": \"class 3\", \"correlation\": 0.9498178965648645, \"num_variants\": 30000.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = alt.Chart(all_corrs).mark_point().encode(\n",
    "    alt.X('num_variants:Q'),\n",
    "    alt.Y('correlation:Q'),\n",
    "    alt.Color('epitope:N'),\n",
    "    tooltip=['num_variants', 'correlation', 'epitope']\n",
    ")\n",
    "\n",
    "chart = base + base.transform_loess('num_variants', 'correlation', groupby=['epitope']).mark_line(size=2.5)\n",
    "chart.save('scipy_results/figures/library_size.pdf')\n",
    "chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
